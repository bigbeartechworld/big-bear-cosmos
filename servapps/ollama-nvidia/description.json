{
  "name": "Ollama - NVIDIA",
  "description": "Get up and running with Llama 3, Mistral, Gemma, and other large language models.",
  "url": "https://hub.docker.com/r/ollama/ollama",
  "longDescription": "Get up and running with Llama 3, Mistral, Gemma, and other large language models.",
  "tags": ["selfhosted","docker","bigbear","bigbearcasaos","container"],
  "repository": "https://github.com/bigbeartechworld",
  "image": "https://cdn.jsdelivr.net/gh/selfhst/icons/png/ollama.png",
  "supported_architectures": ["amd64","arm64"],
  "icon": "https://cdn.jsdelivr.net/gh/selfhst/icons/png/ollama.png"
}
