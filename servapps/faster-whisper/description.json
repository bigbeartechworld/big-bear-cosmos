{
  "name": "Faster-whisper",
  "description": "Faster-whisper is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models. This container provides a Wyoming protocol server for faster-whisper.",
  "url": "https://hub.docker.com/r/linuxserver/faster-whisper",
  "longDescription": "Faster-whisper is a reimplementation of OpenAI's Whisper model using CTranslate2, which is a fast inference engine for Transformer models. This container provides a Wyoming protocol server for faster-whisper.",
  "tags": ["selfhosted","docker","bigbear","bigbearcasaos","container"],
  "repository": "https://github.com/bigbeartechworld",
  "image": "https://cdn.jsdelivr.net/gh/bigbeartechworld/big-bear-universal-apps/apps/faster-whisper/logo.png",
  "supported_architectures": ["amd64"],
  "icon": "https://cdn.jsdelivr.net/gh/bigbeartechworld/big-bear-universal-apps/apps/faster-whisper/logo.png"
}
